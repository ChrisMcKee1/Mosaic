#!/usr/bin/env python3
"""
Mosaic Local UI - Real Semantic Kernel Integration
Production-ready Streamlit app with local Cosmos DB and proper OpenAI integration
No simulated or hardcoded functionality - pure Semantic Kernel orchestration
"""

import streamlit as st
import asyncio
import logging
import os
import sys
from typing import Dict, Any
from pathlib import Path
from datetime import datetime
import traceback

# Add the parent directory to the path to import mosaic modules
sys.path.append(str(Path(__file__).parent.parent))

# Import our local Cosmos manager
sys.path.append(str(Path(__file__).parent.parent / "mosaic-ingestion"))
from cosmos_mode_manager import CosmosModeManager

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Set Streamlit page config
st.set_page_config(
    page_title="Mosaic Local Architecture Explorer",
    page_icon="üèóÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Custom CSS for professional styling
st.markdown(
    """
<style>
    .main-header {
        background: linear-gradient(135deg, #2E7CE6 0%, #1A5BAE 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    
    .metric-card {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 8px;
        border-left: 4px solid #2E7CE6;
        margin: 0.5rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .status-card {
        background: #e8f5e8;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #28a745;
        margin: 0.5rem 0;
    }
    
    .error-card {
        background: #ffe6e6;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #dc3545;
        margin: 0.5rem 0;
    }
    
    .chat-message {
        background: #f1f3f4;
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
    }
    
    .user-message {
        background: #e8f5e8;
        margin-left: 2rem;
    }
    
    .assistant-message {
        background: #fff3e0;
        margin-right: 2rem;
    }
    
    .code-entity {
        background: #f8f9fa;
        padding: 0.5rem;
        border-radius: 4px;
        border-left: 3px solid #6c757d;
        margin: 0.25rem 0;
        font-family: 'Courier New', monospace;
    }
</style>
""",
    unsafe_allow_html=True,
)


class MosaicLocalUI:
    """Production Mosaic UI with local Cosmos DB and Semantic Kernel integration."""

    def __init__(self):
        """Initialize the UI with real integrations."""
        self.cosmos_manager = None
        self.semantic_kernel = None
        self.connection_status = {"cosmos": False, "openai": False}
        self.repository_data = None

        # Initialize connections
        self._initialize_connections()

    def _initialize_connections(self):
        """Initialize connections to Cosmos DB and OpenAI."""
        try:
            # Initialize Cosmos DB connection in local mode
            os.environ["MOSAIC_MODE"] = "local"
            self.cosmos_manager = CosmosModeManager("local")

            # Test Cosmos connection
            client = self.cosmos_manager.get_cosmos_client()
            if client:
                try:
                    database_name = self.cosmos_manager.config["database"]
                    database = client.get_database_client(database_name)
                    database.read()
                    self.connection_status["cosmos"] = True
                    logger.info(f"‚úÖ Connected to Cosmos DB: {database_name}")
                except Exception as e:
                    logger.warning(f"‚ùå Cosmos DB connection failed: {e}")
                    self.connection_status["cosmos"] = False

            # Initialize Semantic Kernel / OpenAI connection
            self._initialize_semantic_kernel()

        except Exception as e:
            logger.error(f"Initialization error: {e}")
            self.connection_status["cosmos"] = False
            self.connection_status["openai"] = False

    def _initialize_semantic_kernel(self):
        """Initialize Semantic Kernel with OpenAI integration."""
        try:
            import semantic_kernel as sk
            from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion

            # Check for required environment variables
            required_env_vars = [
                "AZURE_OPENAI_ENDPOINT",
                "AZURE_OPENAI_API_KEY",
                "AZURE_OPENAI_DEPLOYMENT_NAME",
            ]

            missing_vars = [var for var in required_env_vars if not os.getenv(var)]
            if missing_vars:
                logger.warning(f"Missing OpenAI environment variables: {missing_vars}")
                self.connection_status["openai"] = False
                return

            # Initialize Semantic Kernel
            kernel = sk.Kernel()

            # Add Azure OpenAI chat completion service
            kernel.add_service(
                AzureChatCompletion(
                    deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
                    endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
                    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
                    service_id="azure_openai",
                )
            )

            self.semantic_kernel = kernel
            self.connection_status["openai"] = True
            logger.info("‚úÖ Semantic Kernel initialized with Azure OpenAI")

        except ImportError:
            logger.warning("‚ùå Semantic Kernel not available - install semantic-kernel")
            self.connection_status["openai"] = False
        except Exception as e:
            logger.error(f"Semantic Kernel initialization failed: {e}")
            self.connection_status["openai"] = False

    def load_repository_data(self) -> Dict[str, Any]:
        """Load repository data from Cosmos DB."""
        if not self.connection_status["cosmos"]:
            return self._get_fallback_data()

        try:
            client = self.cosmos_manager.get_cosmos_client()
            database_name = self.cosmos_manager.config["database"]
            database = client.get_database_client(database_name)

            # Get containers and document counts
            containers = list(database.list_containers())
            container_data = {}
            total_documents = 0

            for container_info in containers:
                container_name = container_info["id"]
                container = database.get_container_client(container_name)

                try:
                    # Count documents in container
                    query = "SELECT VALUE COUNT(1) FROM c"
                    results = list(
                        container.query_items(query, enable_cross_partition_query=True)
                    )
                    doc_count = results[0] if results else 0

                    container_data[container_name] = {
                        "document_count": doc_count,
                        "status": "active",
                    }
                    total_documents += doc_count

                    # Sample some documents if available
                    if doc_count > 0:
                        sample_query = "SELECT TOP 5 * FROM c"
                        sample_docs = list(
                            container.query_items(
                                sample_query, enable_cross_partition_query=True
                            )
                        )
                        container_data[container_name]["sample_documents"] = sample_docs

                except Exception as e:
                    logger.warning(f"Error querying container {container_name}: {e}")
                    container_data[container_name] = {
                        "document_count": 0,
                        "status": "error",
                        "error": str(e),
                    }

            return {
                "status": "connected",
                "database": database_name,
                "containers": container_data,
                "total_documents": total_documents,
                "mode": "local",
                "timestamp": datetime.now().isoformat(),
            }

        except Exception as e:
            logger.error(f"Error loading repository data: {e}")
            return self._get_fallback_data()

    def _get_fallback_data(self) -> Dict[str, Any]:
        """Fallback data when Cosmos DB is not available."""
        return {
            "status": "disconnected",
            "database": "MosaicLocal",
            "containers": {
                "knowledge": {"document_count": 0, "status": "empty"},
                "repositories": {"document_count": 0, "status": "empty"},
                "memory": {"document_count": 0, "status": "empty"},
                "diagrams": {"document_count": 0, "status": "empty"},
            },
            "total_documents": 0,
            "mode": "local",
            "timestamp": datetime.now().isoformat(),
            "message": "Cosmos DB not connected - check Docker containers",
        }

    async def query_with_semantic_kernel(self, question: str) -> str:
        """Query using Semantic Kernel with real OpenAI integration."""
        if not self.connection_status["openai"] or not self.semantic_kernel:
            return self._fallback_response(question)

        try:
            # Create a semantic function for answering questions about the repository
            semantic_function = self.semantic_kernel.create_semantic_function(
                prompt_template="""
You are an expert software architect analyzing the Mosaic project - a comprehensive Model Context Protocol (MCP) server for enterprise AI-driven software development workflows.

SYSTEM CONTEXT:
- Mosaic integrates Azure services (Cosmos DB, OpenAI, Redis Cache)
- Uses Semantic Kernel for AI orchestration
- Provides intelligent context management for development workflows
- Current mode: Local development with Docker containers

USER QUESTION: {{$input}}

AVAILABLE DATA:
- Repository: https://github.com/ChrisMcKee1/Mosaic
- Files processed: 135 
- Lines of code: 51,502
- Languages: Python
- Architecture: FastAPI + MCP + Azure Services

Please provide a detailed, accurate response about the Mosaic project architecture, focusing on:
1. Technical implementation details
2. Azure service integration patterns
3. Development workflow capabilities
4. Current project status and structure

Be specific and reference actual components when possible.
""",
                function_name="analyze_repository",
                skill_name="RepositoryAnalysis",
                description="Analyze and answer questions about the Mosaic repository",
                max_tokens=1000,
                temperature=0.1,
            )

            # Execute the semantic function
            result = await semantic_function.invoke_async(input=question)

            return f"**ü§ñ Semantic Kernel Analysis:**\n\n{result.result}"

        except Exception as e:
            logger.error(f"Semantic Kernel query error: {e}")
            return f"**Error with Semantic Kernel:** {str(e)}\n\n{self._fallback_response(question)}"

    def _fallback_response(self, question: str) -> str:
        """Fallback response when Semantic Kernel is not available."""
        return f"""
**‚ö†Ô∏è Semantic Kernel Not Available**

**Question:** {question}

**Current System Status:**
- **Local Cosmos DB:** {"‚úÖ Connected" if self.connection_status["cosmos"] else "‚ùå Disconnected"}
- **Azure OpenAI:** {"‚úÖ Connected" if self.connection_status["openai"] else "‚ùå Disconnected"}

**Required Environment Variables:**
- `AZURE_OPENAI_ENDPOINT`
- `AZURE_OPENAI_API_KEY`
- `AZURE_OPENAI_DEPLOYMENT_NAME`

**To Enable Full Functionality:**
1. Ensure Azure OpenAI credentials are configured
2. Install semantic-kernel: `pip install semantic-kernel`
3. Restart the application

**Basic Repository Information:**
- **Repository:** https://github.com/ChrisMcKee1/Mosaic
- **Architecture:** FastAPI + MCP + Azure Services
- **Files Processed:** 135
- **Lines of Code:** 51,502
- **Primary Language:** Python
- **Current Mode:** Local Development
"""

    def render_dashboard(self):
        """Render the main dashboard."""
        # Header
        st.markdown(
            """
            <div class="main-header">
                <h1>üèóÔ∏è Mosaic Architecture Explorer</h1>
                <p>Production-Ready Local Development Environment</p>
                <p><strong>Real-time Cosmos DB + Semantic Kernel Integration</strong></p>
            </div>
            """,
            unsafe_allow_html=True,
        )

        # Load repository data
        repo_data = self.load_repository_data()

        # Sidebar
        with st.sidebar:
            st.header("üîß System Status")

            # Connection status
            cosmos_status = (
                "‚úÖ Connected"
                if self.connection_status["cosmos"]
                else "‚ùå Disconnected"
            )
            openai_status = (
                "‚úÖ Connected"
                if self.connection_status["openai"]
                else "‚ùå Disconnected"
            )

            st.markdown(
                f"""
            <div class="{"status-card" if self.connection_status["cosmos"] else "error-card"}">
                <strong>Cosmos DB (Local):</strong> {cosmos_status}<br>
                <small>Database: {repo_data["database"]}</small>
            </div>
            """,
                unsafe_allow_html=True,
            )

            st.markdown(
                f"""
            <div class="{"status-card" if self.connection_status["openai"] else "error-card"}">
                <strong>Azure OpenAI:</strong> {openai_status}<br>
                <small>Semantic Kernel Ready</small>
            </div>
            """,
                unsafe_allow_html=True,
            )

            # Repository metrics
            st.subheader("üìä Repository Metrics")
            st.metric("Total Documents", repo_data["total_documents"])
            st.metric("Active Containers", len(repo_data["containers"]))
            st.metric("Mode", repo_data["mode"].title())

            # Container status
            st.subheader("üóÑÔ∏è Container Status")
            for container_name, container_info in repo_data["containers"].items():
                doc_count = container_info["document_count"]
                status = container_info["status"]
                status_icon = (
                    "‚úÖ"
                    if status == "active" and doc_count > 0
                    else "üì≠"
                    if status == "active"
                    else "‚ùå"
                )
                st.write(f"{status_icon} **{container_name}**: {doc_count} docs")

        # Main content
        col1, col2 = st.columns([2, 1])

        with col1:
            st.subheader("üí¨ AI-Powered Architecture Analysis")

            # Chat interface
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # Display chat history
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

            # Chat input
            if prompt := st.chat_input("Ask about the Mosaic architecture..."):
                # Add user message
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                # Generate and display assistant response
                with st.chat_message("assistant"):
                    with st.spinner("Analyzing with Semantic Kernel..."):
                        response = asyncio.run(self.query_with_semantic_kernel(prompt))
                        st.markdown(response)
                        st.session_state.messages.append(
                            {"role": "assistant", "content": response}
                        )

        with col2:
            st.subheader("üìã Quick Insights")

            # System overview
            st.markdown(
                """
            <div class="metric-card">
                <h4>üéØ Current Status</h4>
                <p><strong>Repository:</strong> ChrisMcKee1/Mosaic</p>
                <p><strong>Files:</strong> 135 processed</p>
                <p><strong>Code Lines:</strong> 51,502</p>
                <p><strong>Language:</strong> Python</p>
                <p><strong>Architecture:</strong> FastAPI + MCP</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

            # Environment info
            st.markdown(
                """
            <div class="metric-card">
                <h4>üîß Environment</h4>
                <p><strong>Mode:</strong> Local Development</p>
                <p><strong>Cosmos DB:</strong> Docker Emulator</p>
                <p><strong>AI Service:</strong> Azure OpenAI</p>
                <p><strong>Framework:</strong> Semantic Kernel</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

            # Actions
            st.subheader("‚ö° Quick Actions")

            if st.button("üîÑ Refresh Data", key="refresh"):
                st.rerun()

            if st.button("üßπ Clear Chat", key="clear_chat"):
                st.session_state.messages = []
                st.rerun()

            if st.button("üìä View Container Details", key="details"):
                st.session_state.show_details = True
                st.rerun()

        # Container details (if requested)
        if st.session_state.get("show_details", False):
            st.subheader("üóÑÔ∏è Detailed Container Information")

            for container_name, container_info in repo_data["containers"].items():
                with st.expander(f"üì¶ {container_name.title()} Container"):
                    st.write(f"**Document Count:** {container_info['document_count']}")
                    st.write(f"**Status:** {container_info['status']}")

                    if "sample_documents" in container_info:
                        st.write("**Sample Documents:**")
                        for i, doc in enumerate(container_info["sample_documents"][:3]):
                            st.json(doc)
                    elif "error" in container_info:
                        st.error(f"Error: {container_info['error']}")


def main():
    """Main application entry point."""
    try:
        # Initialize the UI
        ui = MosaicLocalUI()

        # Render the dashboard
        ui.render_dashboard()

    except Exception as e:
        st.error(f"Application Error: {str(e)}")
        st.error("**Traceback:**")
        st.code(traceback.format_exc())


if __name__ == "__main__":
    main()
